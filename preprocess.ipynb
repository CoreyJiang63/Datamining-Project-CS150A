{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jyc02\\anaconda3\\lib\\site-packages\\pyspark\\sql\\context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SQLContext, SparkContext\n",
    "from pyspark.sql.functions import mean, col, udf\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "sc = SparkContext('local')\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sqlc.read.csv('data/train.csv', sep='\\t', header=True)\n",
    "test = sqlc.read.csv('data/test.csv', sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = ['Row','Step Start time','First Transaction Time','Correct Transaction Time','Step End Time','Step Duration (sec)',\\\n",
    "    'Correct Step Duration (sec)','Error Step Duration (sec)','Incorrects','Hints','Corrects']\n",
    "\n",
    "for col_dropped in dropped:\n",
    "    train = train.drop(col_dropped)\n",
    "    test = test.drop(col_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def udf_process(func, typ):\n",
    "    return(f.udf(func, typ))\n",
    "def newcol(col_name, operation):\n",
    "    global train, test\n",
    "    train = train.withColumn(col_name, operation)\n",
    "    test = test.withColumn(col_name, operation)\n",
    "def dropcol(col_name):\n",
    "    global train, test\n",
    "    train = train.drop(col_name)\n",
    "    test = test.drop(col_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unit(hierac): \n",
    "    return hierac.split(',')[0]  \n",
    "def generate_section(hierac):\n",
    "    return hierac.split(',')[1]\n",
    "\n",
    "unit_sep = udf(generate_unit, StringType())\n",
    "section_sep = udf(generate_section, StringType())\n",
    "train = train.withColumn('step Unit', unit_sep(train['step Hierarchy']))\n",
    "test = test.withColumn('Problem Unit', unit_sep(test['Problem Hierarchy']))\n",
    "train = train.withColumn('Problem Section', section_sep(train['Problem Hierarchy']))\n",
    "test = test.withColumn('Problem Section', section_sep(test['Problem Hierarchy']))\n",
    "train = train.drop('Problem Hierarchy')\n",
    "test = test.drop('Problem Hierarchy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process KC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_KCnum(kc):\n",
    "    if kc:\n",
    "        return kc.count('~~')+1\n",
    "    else:\n",
    "        return 0\n",
    "KCcnt = udf(generate_KCnum, IntegerType())\n",
    "train = train.withColumn('KC Count', KCcnt(train['KC(Default)']))\n",
    "test = test.withColumn('KC Count', KCcnt(test['KC(Default)']))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Opportunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opportunity_avg(opp):\n",
    "    if not opp:\n",
    "        return 0.0\n",
    "    nums = [int(i) for i in opp.split('~~')]\n",
    "    return sum(nums)/len(nums)*1.0\n",
    "\n",
    "oppavg = udf(opportunity_avg, FloatType())\n",
    "train = train.withColumn('Opportunity Avg', oppavg(train['Opportunity(Default)']))\n",
    "test = test.withColumn('Opportunity Avg', oppavg(test['Opportunity(Default)']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Discrete repetitive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_cols = ['Anon Student Id','Problem Name','Problem Unit','Problem Section','Step Name']\n",
    "def vectorize(col):\n",
    "    global train, test\n",
    "    sid_dict = {}\n",
    "    un = train.union(test)\n",
    "    unique = un.select(col).distinct().collect()\n",
    "    sids = [i[col] for i in unique]\n",
    "    for idx, sid in enumerate(sids):\n",
    "        sid_dict[sid] = idx\n",
    "\n",
    "    def vect(sid):\n",
    "        return sid_dict[sid]\n",
    "    udfvect = udf(vect, IntegerType())\n",
    "    train = train.withColumn('vectorized'+col, udfvect(col))\n",
    "    train = train.drop(col)\n",
    "    train = train.withColumnRenamed('vectorized'+col, col)\n",
    "    test = test.withColumn('vectorized'+col, udfvect(col))\n",
    "    test = test.drop(col)\n",
    "    test = test.withColumnRenamed('vectorized'+col, col)\n",
    "\n",
    "for c in discrete_cols:\n",
    "    vectorize(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfa = train.filter(train['Correct First Attempt']=='1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "global train, test\n",
    "student_dict = {}\n",
    "correct_studentGroup = cfa.groupby('Anon Student Id').count()\n",
    "studentGroup = train.groupby('Anon Student Id').count()\n",
    "student_joined = correct_studentGroup.join(studentGroup, studentGroup['Anon Student Id'] == correct_studentGroup['Anon Student Id'])\n",
    "\n",
    "student_correct_rate = correct_studentGroup.join(studentGroup, studentGroup['Anon Student Id'] == correct_studentGroup['Anon Student Id']).drop(studentGroup['Anon Student Id'])\n",
    "personal_rate = student_correct_rate.select('Anon Student Id', (correct_studentGroup['count']/studentGroup['count']))\n",
    "personal_rate = personal_rate.withColumn('Personal Correct Rate', personal_rate['(count / count)']).drop('(count / count)')\n",
    "\n",
    "tmp_sum, cnt = 0, 0\n",
    "for row in personal_rate.collect():\n",
    "    tmp_sum += row['Personal Correct Rate']\n",
    "    cnt += 1\n",
    "personal_mean = tmp_sum/cnt\n",
    "\n",
    "for row in personal_rate.collect():\n",
    "    student_dict[row['Anon Student Id']] = row['Personal Correct Rate']\n",
    "def get_rate_from_id(idx):\n",
    "    if idx in student_dict.keys():\n",
    "        return float(student_dict[idx])\n",
    "    else:\n",
    "        return personal_mean\n",
    "        \n",
    "udf_getRate = udf(get_rate_from_id, FloatType())\n",
    "train = train.withColumn('Personal Rate', udf_getRate('Anon Student Id'))\n",
    "test = test.withColumn('Personal Rate', udf_getRate('Anon Student Id'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group By Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_problem():   \n",
    "    global train, test\n",
    "    problem_dict = {}\n",
    "    correct_problemGroup = cfa.groupby('Problem Name').count()\n",
    "    problemGroup = train.groupby('Problem Name').count()\n",
    "    problem_joined = correct_problemGroup.join(problemGroup, problemGroup['Problem Name'] == correct_problemGroup['Problem Name'])\n",
    "\n",
    "    problem_correct_rate = correct_problemGroup.join(problemGroup, problemGroup['Problem Name'] == correct_problemGroup['Problem Name']).drop(problemGroup['Problem Name'])\n",
    "    problem_rate = problem_correct_rate.select('Problem Name', (correct_problemGroup['count']/problemGroup['count']))\n",
    "    problem_rate = problem_rate.withColumn('Problem Correct Rate', problem_rate['(count / count)']).drop('(count / count)')\n",
    "\n",
    "    tmp_sum, cnt = 0, 0\n",
    "    for row in problem_rate.collect():\n",
    "        tmp_sum += row['Problem Correct Rate']\n",
    "        cnt += 1\n",
    "    problem_mean = tmp_sum/cnt\n",
    "\n",
    "    for row in problem_rate.collect():\n",
    "        problem_dict[row['Problem Name']] = row['Problem Correct Rate']\n",
    "    def get_rate_from_prb(idx):\n",
    "        if idx in problem_dict.keys():\n",
    "            return float(problem_dict[idx])\n",
    "        else:\n",
    "            return problem_mean\n",
    "            \n",
    "    udf_getRate = udf(get_rate_from_prb, FloatType())\n",
    "    train = train.withColumn('Problem Rate', udf_getRate('Problem Name'))\n",
    "    test = test.withColumn('Problem Rate', udf_getRate('Problem Name'))\n",
    "group_by_problem()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group By Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_step():   \n",
    "    global train, test\n",
    "    step_dict = {}\n",
    "    correct_stepGroup = cfa.groupby('Step Name').count()\n",
    "    stepGroup = train.groupby('Step Name').count()\n",
    "    step_joined = correct_stepGroup.join(stepGroup, stepGroup['Step Name'] == correct_stepGroup['Step Name'])\n",
    "\n",
    "    step_correct_rate = correct_stepGroup.join(stepGroup, stepGroup['Step Name'] == correct_stepGroup['Step Name']).drop(stepGroup['step Name'])\n",
    "    step_rate = step_correct_rate.select('Step Name', (correct_stepGroup['count']/stepGroup['count']))\n",
    "    step_rate = step_rate.withColumn('Step Correct Rate', step_rate['(count / count)']).drop('(count / count)')\n",
    "\n",
    "    tmp_sum, cnt = 0, 0\n",
    "    for row in step_rate.collect():\n",
    "        tmp_sum += row['Step Correct Rate']\n",
    "        cnt += 1\n",
    "    step_mean = tmp_sum/cnt\n",
    "\n",
    "    for row in step_rate.collect():\n",
    "        step_dict[row['Step Name']] = row['Step Correct Rate']\n",
    "    def get_rate_from_stp(idx):\n",
    "        if idx in step_dict.keys():\n",
    "            return float(step_dict[idx])\n",
    "        else:\n",
    "            return step_mean\n",
    "            \n",
    "    udf_getRate = udf(get_rate_from_stp, FloatType())\n",
    "    train = train.withColumn('Step Rate', udf_getRate('Step Name'))\n",
    "    test = test.withColumn('Step Rate', udf_getRate('Step Name'))\n",
    "group_by_step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group By KC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_kc():   \n",
    "    global train, test\n",
    "    kc_dict = {}\n",
    "    correct_kcGroup = cfa.groupby('KC(Default)').count()\n",
    "    kcGroup = train.groupby('KC(Default)').count()\n",
    "    kc_joined = correct_kcGroup.join(kcGroup, kcGroup['KC(Default)'] == correct_kcGroup['KC(Default)'])\n",
    "\n",
    "    kc_correct_rate = correct_kcGroup.join(kcGroup, kcGroup['KC(Default)'] == correct_kcGroup['KC(Default)']).drop(kcGroup['KC(Default)'])\n",
    "    kc_rate = kc_correct_rate.select('KC(Default)', (correct_kcGroup['count']/kcGroup['count']))\n",
    "    kc_rate = kc_rate.withColumn('KC Correct Rate', kc_rate['(count / count)']).drop('(count / count)')\n",
    "\n",
    "    tmp_sum, cnt = 0, 0\n",
    "    for row in kc_rate.collect():\n",
    "        tmp_sum += row['KC Correct Rate']\n",
    "        cnt += 1\n",
    "    kc_mean = tmp_sum/cnt\n",
    "\n",
    "    for row in kc_rate.collect():\n",
    "        kc_dict[row['KC(Default)']] = row['KC Correct Rate']\n",
    "    def get_rate_from_kc(idx):\n",
    "        if idx in kc_dict.keys():\n",
    "            return float(kc_dict[idx])\n",
    "        else:\n",
    "            return kc_mean\n",
    "            \n",
    "    udf_getRate = udf(get_rate_from_kc, FloatType())\n",
    "    train = train.withColumn('KC Rate', udf_getRate('KC(Default)'))\n",
    "    test = test.withColumn('KC Rate', udf_getRate('KC(Default)'))\n",
    "group_by_kc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('KC(Default)')\n",
    "test = test.drop('KC(Default)')\n",
    "train.toPandas().to_csv('data/train_preprocessed.csv', sep='\\t', header=True, index = False)\n",
    "test.toPandas().to_csv('data/test_preprocessed.csv', sep='\\t', header=True, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b9fa3c382c4e666e7938e52c8239e3fd78167be64dcb23ecde2a8506e6ccd3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
