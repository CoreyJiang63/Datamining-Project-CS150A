{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import lightgbm\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232744, 12)\n",
      "(666, 12)\n",
      "   Problem View  KC Count  Opportunity Avg  Anon Student Id  Problem Name  \\\n",
      "0             1         0              0.0              170            69   \n",
      "1             1         0              0.0              170            69   \n",
      "2             1         1              1.0              170            69   \n",
      "3             1         3              1.0              170            69   \n",
      "4             1         1              1.0              170            69   \n",
      "\n",
      "   Problem Unit  Problem Section  Step Name  Personal Rate  Problem Rate  \\\n",
      "0            15               33      34382       0.748749      0.710197   \n",
      "1            15               33      14346       0.748749      0.710197   \n",
      "2            15               33      58300       0.748749      0.710197   \n",
      "3            15               33      60417       0.748749      0.710197   \n",
      "4            15               33      30098       0.748749      0.710197   \n",
      "\n",
      "   Step Rate   KC Rate  \n",
      "0   0.840631  0.655650  \n",
      "1   0.830699  0.655650  \n",
      "2   0.966979  0.966979  \n",
      "3   0.404477  0.443541  \n",
      "4   0.760107  0.817953  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train_preprocessed.csv', sep='\\t')\n",
    "test = pd.read_csv('data/test_preprocessed.csv', sep='\\t')\n",
    "train = train.drop(['Opportunity(Default)'], axis=1)\n",
    "test = test.drop(['Opportunity(Default)'], axis=1)\n",
    "\n",
    "# Separation of dataset\n",
    "train_x = train.dropna()\n",
    "train_y = np.array(train_x['Correct First Attempt']).astype(int)\n",
    "train_x = train_x.drop(['Correct First Attempt'],axis = 1)\n",
    "test_x = test.dropna()\n",
    "test_y = np.array(test_x['Correct First Attempt']).astype(int)\n",
    "test_x = test_x.drop(['Correct First Attempt'],axis = 1)\n",
    "\n",
    "print(train_x.shape[:])\n",
    "print(test_x.shape[:])\n",
    "print(train_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(ypred, y):\n",
    "    distance = np.square(np.subtract(ypred, y))\n",
    "    avg = np.mean(distance)\n",
    "    return np.sqrt(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    norm = np.linalg.norm(x, ord=2, axis=1, keepdims=True)\n",
    "    return x/norm\n",
    "\n",
    "drop_cols = ['Anon Student Id', 'Problem Name', 'Problem Unit', 'Problem Section', 'Step Name']\n",
    "tmp_train = train_x.drop(drop_cols, axis=1)\n",
    "tmp_test = test_x.drop(drop_cols, axis=1)\n",
    "train_norm_x = normalize(tmp_train)\n",
    "test_norm_x = normalize(tmp_test)\n",
    "for c in drop_cols:\n",
    "    train_norm_x[c] = train_x[c]\n",
    "    test_norm_x[c] = test_x[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree bagging error 0.36569588934452557\n"
     ]
    }
   ],
   "source": [
    "tree = tree.DecisionTreeClassifier()\n",
    "model = BaggingRegressor(base_estimator=tree, n_estimators=100, max_samples=1.0, bootstrap=True)\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"tree bagging error\", loss_function(result, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor error 0.38955283124050977\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=(100, 5, 100), activation='tanh', solver='adam')\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"MLPRegressor error\", loss_function(result, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression error 0.43495883620084\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2')\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"Logistic Regression error\", loss_function(result, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest error 0.3685936261810034\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"RandomForest error\", loss_function(result, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN error 0.3981941217026672\n"
     ]
    }
   ],
   "source": [
    "model = neighbors.KNeighborsRegressor()\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"KNN error\", loss_function(result, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Regression error 0.3927966234985601\n"
     ]
    }
   ],
   "source": [
    "model = DummyRegressor()\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"Dummy Regression error\", loss_function(result, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost error 0.427999045773683\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"XGBoost error\", loss_function(result, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost error 0.38108937717196817\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostRegressor()\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"Adaboost error\", loss_function(result, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Decision Tree error 0.4155390146215788\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=200)\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"Gradient Decision Tree error\", loss_function(result, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn bagging error 0.3860914329463872\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsRegressor()\n",
    "model = BaggingRegressor(base_estimator=knn, n_estimators=100, max_samples=1.0, bootstrap=True)\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"knn bagging error\", loss_function(result, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
