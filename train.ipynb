{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import lightgbm\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232744, 12)\n",
      "(666, 12)\n",
      "   Problem View  KC Count  Opportunity Avg  Anon Student Id  Problem Name  \\\n",
      "0             1         0              0.0              170            69   \n",
      "1             1         0              0.0              170            69   \n",
      "2             1         1              1.0              170            69   \n",
      "3             1         3              1.0              170            69   \n",
      "4             1         1              1.0              170            69   \n",
      "\n",
      "   Problem Unit  Problem Section  Step Name  Personal Rate  Problem Rate  \\\n",
      "0            15               33      34382       0.748749      0.710197   \n",
      "1            15               33      14346       0.748749      0.710197   \n",
      "2            15               33      58300       0.748749      0.710197   \n",
      "3            15               33      60417       0.748749      0.710197   \n",
      "4            15               33      30098       0.748749      0.710197   \n",
      "\n",
      "   Step Rate   KC Rate  \n",
      "0   0.840631  0.655650  \n",
      "1   0.830699  0.655650  \n",
      "2   0.966979  0.966979  \n",
      "3   0.404477  0.443541  \n",
      "4   0.760107  0.817953  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train_preprocessed.csv', sep='\\t')\n",
    "test = pd.read_csv('data/test_preprocessed.csv', sep='\\t')\n",
    "train = train.drop(['Opportunity(Default)'], axis=1)\n",
    "test = test.drop(['Opportunity(Default)'], axis=1)\n",
    "\n",
    "# Separation of dataset\n",
    "train_x = train.dropna()\n",
    "train_y = np.array(train_x['Correct First Attempt']).astype(int)\n",
    "train_x = train_x.drop(['Correct First Attempt'],axis = 1)\n",
    "test_x = test.dropna()\n",
    "test_y = np.array(test_x['Correct First Attempt']).astype(int)\n",
    "test_x = test_x.drop(['Correct First Attempt'],axis = 1)\n",
    "\n",
    "print(train_x.shape[:])\n",
    "print(test_x.shape[:])\n",
    "print(train_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def loss_function(ypred, y):\n",
    "    distance = np.square(np.subtract(ypred, y))\n",
    "    avg = np.mean(distance)\n",
    "    return np.sqrt(avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree 0.5927489783638191\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model = model.fit(train_x, train_y)\n",
    "ypred = model.predict(test_x)\n",
    "ypred = ypred.astype(float)\n",
    "print('Decision Tree', loss_function(ypred, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN error 0.39992491787826867\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "model = neighbors.KNeighborsRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "result = model.predict(test_x)\n",
    "print(\"KNN error\", loss_function(result, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Regression error 0.3927966234985601\n"
     ]
    }
   ],
   "source": [
    "model = DummyRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "result = model.predict(test_x)\n",
    "print(\"Dummy Regression error\", loss_function(result, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest error 0.5164275819971735\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "result = model.predict(test_x)\n",
    "print(\"RandomForest error\", loss_function(result, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost error 0.5466249160062124\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "result = model.predict(test_x)\n",
    "print(\"XGBoost error\", loss_function(result, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost error 0.5382797121241062\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "result = model.predict(test_x)\n",
    "print(\"Adaboost error\", loss_function(result, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Decision Tree error 0.5507297915523577\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=200)\n",
    "model.fit(train_x, train_y)\n",
    "result = model.predict(test_x)\n",
    "print(\"Gradient Decision Tree error\", loss_function(result, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression error 0.43495883620084\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2')\n",
    "model.fit(train_x, train_y)\n",
    "result = model.predict(test_x)\n",
    "print(\"Logistic Regression error\", loss_function(result, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor error 0.387724036278484\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=(100, 5, 100), activation='tanh', solver='adam')\n",
    "model.fit(train_x, train_y)\n",
    "result = model.predict(test_x)\n",
    "print(\"MLPRegressor error\", loss_function(result, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging avoids overfitting of data and is used for both regression and classification models, specifically for decision tree algorithms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree bagging error 0.5173741160668709\n"
     ]
    }
   ],
   "source": [
    "tree = tree.DecisionTreeClassifier()\n",
    "model = BaggingRegressor(base_estimator=tree, n_estimators=100, max_samples=1.0, bootstrap=True)\n",
    "model.fit(train_x, train_y)\n",
    "result = model.predict(test_x)\n",
    "print(\"tree bagging error\", loss_function(result, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn bagging error 0.3894057380532917\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsRegressor()\n",
    "model = BaggingRegressor(base_estimator=knn, n_estimators=100, max_samples=1.0, bootstrap=True)\n",
    "model.fit(train_x, train_y)\n",
    "result = model.predict(test_x)\n",
    "print(\"knn bagging error\", loss_function(result, test_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    norm = np.linalg.norm(x, ord=2, axis=1, keepdims=True)\n",
    "    return x/norm\n",
    "\n",
    "drop_cols = ['Anon Student Id', 'Problem Name', 'Problem Unit', 'Problem Section', 'Step Name']\n",
    "tmp_train = train_x.drop(drop_cols, axis=1)\n",
    "tmp_test = test_x.drop(drop_cols, axis=1)\n",
    "train_norm_x = normalize(tmp_train)\n",
    "test_norm_x = normalize(tmp_test)\n",
    "for c in drop_cols:\n",
    "    train_norm_x[c] = train_x[c]\n",
    "    test_norm_x[c] = test_x[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor error 0.39197824823498756\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=(100, 5, 100), activation='tanh', solver='adam')\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"MLPRegressor error\", loss_function(result, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression error 0.43495883620084\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2')\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"Logistic Regression error\", loss_function(result, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest error 0.3691960261239356\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(train_norm_x, train_y)\n",
    "result = model.predict(test_norm_x)\n",
    "print(\"RandomForest error\", loss_function(result, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b9fa3c382c4e666e7938e52c8239e3fd78167be64dcb23ecde2a8506e6ccd3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
